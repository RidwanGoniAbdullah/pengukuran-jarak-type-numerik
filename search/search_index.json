{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Biodata \u00b6 Selamat Datang di Halaman Tugas Penambangan Data \u00b6 Nama : Ridwan Goni Abdullah NIM : 180411100056 Kelas : Penambangan Data 5C Dosen Pengampu : Mula'ab,S.SI.,M.kom Jurusan : Teknik Informatika Alamat : jl. kusumabangsa no:14 MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$']]} });","title":"index"},{"location":"#biodata","text":"","title":"Biodata"},{"location":"#selamat-datang-di-halaman-tugas-penambangan-data","text":"Nama : Ridwan Goni Abdullah NIM : 180411100056 Kelas : Penambangan Data 5C Dosen Pengampu : Mula'ab,S.SI.,M.kom Jurusan : Teknik Informatika Alamat : jl. kusumabangsa no:14 MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$']]} });","title":"Selamat Datang di Halaman Tugas Penambangan Data"},{"location":"Mengukur Jarak Tipe Numerik/","text":"Mengukur Jarak Tipe Numerik \u00b6 Salah satu tantangan dalam era ini dengan datatabase yang memiliki banyak tipe data. Mengukur jarak adalah komponen utama dalam algoritma clustering berbasis jarak. Alogritma seperit Algoritma Partisioning misal K-Mean, K-medoidm dan fuzzy c-mean dan rough clustering bergantung pada jarak untuk melakukan pengelompokkan Sebelum menjelaskan tentang beberapa macam ukuran jarak, kita mendefinisikan terlebih dahulu yaiut v1,v2v1,v2 menyatakandua vektor yang menyatakan v1=x1,x2,...,xn,v2=y1,y2,...,yn,v1=x1,x2,...,xn,v2=y1,y2,...,yn, dimana xi,yixi,yi disebut attribut. Ada beberapa ukuran similaritas datau ukuran jarak, diantaranya Minkowski Distance \u00b6 Kelompk Minkowski diantaranya adalah Euclidean distance dan Manhattan distance, yang menjadi kasus khusus dari Minkowski distance. Minkowski distance dinyatakan dengan $$ d _ { \\operatorname { man } } = \\sum _ { i = 1 } ^ { n } \\left| x _ { i } - y _ { i } \\right| $$ Euclidean distance \u00b6 Jarak yang paling terkenal yang digunakan untuk data numerik adalah jarak Euclidean. Ini adalah kasus khusus dari jarak Minkowski ketika m = 2. Jarak Euclidean berkinerja baik ketika digunakan untuk kumpulan data cluster kompak atau terisolasi . Meskipun jarak Euclidean sangat umum dalam pengelompokan, ia memiliki kelemahan: jika dua vektor data tidak memiliki nilai atribut yang sama, kemungkin memiliki jarak yang lebih kecil daripada pasangan vektor data lainnya yang mengandung nilai atribut yang sama. Masalah lain dengan jarak Euclidean sebagai fitur skala terbesar akan mendominasi yang lain. Normalisasi fitur kontinu adalah solusi untuk mengatasi kelemahan ini. Average Distance \u00b6 Berkenaan dengan kekurangan dari Jarak Euclidian Distance diatas, rata rata jarak adala versi modikfikasid ari jarak Euclidian untuk memperbaiki hasil. Untuk dua titik x,yx,y dalam ruang dimensi nn, rata-rata jarak didefinisikan dengan $$ d _ { a v e } = \\left ( \\frac { 1 } { n } \\sum _ { i = 1 } ^ { n } ( x _ { i } - y _ { i } ) ^ { 2 } \\right) ^ { \\frac { 1 } { 2 } } $$ Weighted euclidean distance \u00b6 Jika berdasarkan tingkatan penting dari masing masing atribut ditentukan, maka Weighted Euclidean distance adalah modifikisasi lain dari jarak Euclidean distance yang dapat digunakan. Ukuran ini dirumuskan dengan $$ d _ { w e } = \\left ( \\sum _ { i = 1 } ^ { n } w _ { i } ( x _ { i } - y _ { i } \\right) ^ { 2 } ) ^ { \\frac { 1 } { 2 } } $$ dimana wiwi adalah bobot yang diberikan pada atribut ke i. Chord distance \u00b6 Chord distance adalah salah satu ukuran jarak modifikasi Euclidean distance untuk mengatasi kekurangan dari Euclidean distance. Ini dapat dipecahkan juga dengan menggunakan skala pengukuran yang baik. Jarak ini dapat juga dihitung dari data yang tidak dinormalisasi . Chord distance didefinisikan dengan $$ d _ { \\text {chord} } = \\left ( 2 - 2 \\frac { \\sum _ { i = 1 } ^ { n } x _ { i } y _ { i } } { | x | _ { 2 } | y | _ { 2 } } \\right) ^ { \\frac { 1 } { 2 } } $$ Mahalanobis distance \u00b6 Mahalanobis distance berdasarkan data berbeda dengan Euclidean dan Manhattan distances yang bebas antra data dengan data yang lain. Jarak Mahalanobis yang teratur dapat digunakan untuk mengekstraksi hyperellipsoidal clusters. Jarak Mahalanobis dapat mengurangi distorsi yang disebabkan oleh korelasi linier antara fitur dengan menerapkan transformasi pemutihan ke data atau dengan menggunakan kuadrat Jarak mahalanobis. Mahalanobis distance dinyatakan dengan $$ d _ { m a h } = \\sqrt { ( x - y ) S ^ { - 1 } ( x - y ) ^ { T } } $$ diman S adalah matrik covariance data. Cosine measure \u00b6 Ukuran Cosine similarity lebih banyak digunakan dalam similaritas dokumen dan dinyatakan dengan $$ Cosine(x,y)=\\frac { \\sum _ { i = 1 } ^ { n } x _ { i } y _ { i } } { | x | _ { 2 } | y | _ { 2 } } $$ Pearson correlation \u00b6 Pearson correlation banyak digunakan dalam data expresi gen. Ukuran similaritas ini menghitung similaritas antara duan bentuk pola expresi gen. Pearson correlation didefinisikan dengan $$ Pearson ( x , y ) = \\frac { \\sum _ { i = 1 } ^ { n } ( x _ { i } - \\mu _ { x } ) ( y _ { i } - \\mu _ { y } ) } { \\sqrt { \\sum _ { i = 1 } ^ { n } ( x _ { i } - y _ { i } ) ^ { 2 } } \\sqrt { \\sum _ { i = 1 } ^ { n } ( x _ { i } - y _ { i } ) ^ { 2 } } } $$ Mengukur Jarak Atribut Binary \u00b6 Mari kita lihat similaritas dan desimilirity untuk objek yang dijelaskan oleh atribut biner simetris atau asimetris. Aatribut biner hanya memiliki dua status: 0 dan 1 Contoh atribut perokok menggambarkan seorang pasien, misalnya, 1 menunjukkan bahwa pasien merokok, sedangkan 0 menunjukkan pasien tidak merokok. Memperlakukan atribut biner sebagai atribut numerik tidak diperkenankan. Oleh karena itu, metode khusus untuk data biner diperlukan untuk membedakan komputasi. Jadi, bagaimana kita bisa menghitung ketidaksamaan antara dua atribut biner? \u201dSatu pendekatan melibatkan penghitungan matriks ketidaksamaan dari data biner yang diberikan. Jika semua atribut biner dianggap memiliki bobot yang sama, kita memiliki tabel kontingensi 2\u00d722\u00d72 di mana qq adalah jumlah atribut yang sama dengan 1 untuk kedua objek ii dan jj, rr adalah jumlah atribut yang sama dengan 1 untuk objek ii tetapi 0 untuk objek jj, ss adalah jumlah atribut yang sama dengan 0 untuk objek ii tetapi 1 untuk objek jj, dan tt adalah jumlah atribut yang sama dengan 0 untuk kedua objek ii dan jj. Jumlah total atribut adalah pp, di mana p=q+r+s+tp=q+r+s+t Ingatlah bahwa untuk atribut biner simetris, masing-masing nilai bobot yang sama.Dissimilarity yang didasarkan pada atribut aymmetric binary disebut symmetric binary dissimilarity. Jika objek i dan j dinyatakan sebagai atribut biner simetris, maka dissimilarity antarii dan jj adalah $$ d ( i , j ) = \\frac { r + s } { q + r + s + t } $$ Untuk atribut biner asimetris, kedua kondisi tersebut tidak sama pentingnya, seperti hasil positif (1) dan negatif (0) dari tes penyakit. Diberikan dua atribut biner asimetris, pencocokan keduanya 1 (kecocokan positif) kemudian dianggap lebih signifikan daripada kecocokan negatif. Ketidaksamaan berdasarkan atribut-atribut ini disebut asimetris biner dissimilarity, di mana jumlah kecocokan negatif, t, dianggap tidak penting dan dengan demikian diabaikan. Berikut perhitungannya $$ d ( i , j ) = \\frac { r + s } { q + r + s } $$ Kita dapat mengukur perbedaan antara dua atribut biner berdasarkan pada disimilarity. Misalnya, biner asimetris kesamaan antara objek ii dan jj dapat dihitung dengan $$ \\operatorname { sim } ( i , j ) = \\frac { q } { q + r + s } = 1 - d ( i , j ) $$ Mengukur Jarak Tipe categorical \u00b6 Overlay Metric \u00b6 Ketika semua atribut adalah bertipe nominal, ukuran jarak yang paling sederhana adalah dengan Ovelay Metric (OM) yang dinyatakan dengan $$ d ( x , y ) = \\sum _ { i = 1 } ^ { n } \\delta ( a _ { i } ( x ) , a _ { i } ( y ) ) $$ OM banyak digunakan oleh instance-based learning dan locally weighted learning. Jelas sekali , ini sedikit beruk untuk mengukur jarak antara masing-masing pasangan sample, karena gagal memanfaatkan tambahan informasi yang diberikan oleh nilai atribut nominal yang bisa membantu dalam generalisasi. Value Difference Metric (VDM) \u00b6 VDM dikenalkan oleh Standfill and Waltz, versi sederhana dari VDM tanpa skema pembobotan didefinsisikan dengan $$ d ( x , y ) = \\sum _ { i = 1 } ^ { n } \\sum _ { c = 1 } ^ { C } \\left| P ( c | a _ { i } ( x ) ) - P ( c | a _ { i } ( y ) ) \\right | $$ VDM mengasumsikan bahwa dua nilai dari atribut adalah lebih dekat jika memiliki klasifikasi sama. Pendekatan lain berbasi probabilitas adalah SFM (Short and Fukunaga Metric) yang kemudian dikembangkan oleh Myles dan Hand dan didefinisikan dengan $$ d ( x , y ) = \\sum _ { c = 1 } ^ { C } \\left | P ( c | x ) - P ( c | y ) \\right| $$ Minimum Risk Metric (MRM) \u00b6 Ukuran ini dipresentasikan oleh Blanzieri and Ricci, berbeda dari SFM yaitu meminimumkan selisih antara kesalahan berhingga dan kesalahan asymtotic. MRM meminimumkan risk of misclassification yang didefinisikan dengan $$ d ( x , y ) = \\sum _ { c = 1 } ^ { C } P ( c | x ) ( 1 - P ( c | y ) ) $$ Mengukur Jarak Tipe Ordinal \u00b6 Nilai-nilai atribut ordinal memiliki urutan atau peringkat, namun besarnya antara nilai-nilai berturut-turut tidak diketahui. Contohnya tingkatan kecil, sedang, besar untuk atribut ukuran. Atribut ordinal juga dapat diperoleh dari diskritisasi atribut numerik dengan membuat rentang nilai ke dalam sejumlah kategori tertentu. $$ z _ { i f } = \\frac { r _ { i f } - 1 } { M _ { f } - 1 } $$ Menghitung Jarak Tipe Campuran \u00b6 Menghitung ketidaksamaan antara objek dengan atribut campuran yang berupa nominal, biner simetris, biner asimetris, numerik, atau ordinal yang ada pada kebanyakan databasae dapat dinyatakan dengan memproses semua tipe atribut secara bersamaan. Salah satu teknik tersebut menggabungkan atribut yang berbeda ke dalam matriks ketidaksamaan tunggal dan menyatakannya dengan skala interval antar [0,0,1.0][0,0,1.0]. Misalkan data berisi atribut pp tipe campuran. Ketidaksamaan (disimilarity ) antara objek ii dan jj dinyatakan dengan $$ d ( i , j ) = \\frac { \\sum _ { f = 1 } ^ { p } \\delta _ { i j } ^ { ( f ) } d _ { i j } ^ { ( f ) } } { \\sum _ { f = 1 } ^ { p } \\delta _ { i j } ^ { ( f ) } } $$","title":"statistik deskriptif"},{"location":"Mengukur Jarak Tipe Numerik/#mengukur-jarak-tipe-numerik","text":"Salah satu tantangan dalam era ini dengan datatabase yang memiliki banyak tipe data. Mengukur jarak adalah komponen utama dalam algoritma clustering berbasis jarak. Alogritma seperit Algoritma Partisioning misal K-Mean, K-medoidm dan fuzzy c-mean dan rough clustering bergantung pada jarak untuk melakukan pengelompokkan Sebelum menjelaskan tentang beberapa macam ukuran jarak, kita mendefinisikan terlebih dahulu yaiut v1,v2v1,v2 menyatakandua vektor yang menyatakan v1=x1,x2,...,xn,v2=y1,y2,...,yn,v1=x1,x2,...,xn,v2=y1,y2,...,yn, dimana xi,yixi,yi disebut attribut. Ada beberapa ukuran similaritas datau ukuran jarak, diantaranya","title":"Mengukur Jarak Tipe Numerik"},{"location":"Mengukur Jarak Tipe Numerik/#minkowski-distance","text":"Kelompk Minkowski diantaranya adalah Euclidean distance dan Manhattan distance, yang menjadi kasus khusus dari Minkowski distance. Minkowski distance dinyatakan dengan $$ d _ { \\operatorname { man } } = \\sum _ { i = 1 } ^ { n } \\left| x _ { i } - y _ { i } \\right| $$","title":"Minkowski Distance"},{"location":"Mengukur Jarak Tipe Numerik/#euclidean-distance","text":"Jarak yang paling terkenal yang digunakan untuk data numerik adalah jarak Euclidean. Ini adalah kasus khusus dari jarak Minkowski ketika m = 2. Jarak Euclidean berkinerja baik ketika digunakan untuk kumpulan data cluster kompak atau terisolasi . Meskipun jarak Euclidean sangat umum dalam pengelompokan, ia memiliki kelemahan: jika dua vektor data tidak memiliki nilai atribut yang sama, kemungkin memiliki jarak yang lebih kecil daripada pasangan vektor data lainnya yang mengandung nilai atribut yang sama. Masalah lain dengan jarak Euclidean sebagai fitur skala terbesar akan mendominasi yang lain. Normalisasi fitur kontinu adalah solusi untuk mengatasi kelemahan ini.","title":"Euclidean distance"},{"location":"Mengukur Jarak Tipe Numerik/#average-distance","text":"Berkenaan dengan kekurangan dari Jarak Euclidian Distance diatas, rata rata jarak adala versi modikfikasid ari jarak Euclidian untuk memperbaiki hasil. Untuk dua titik x,yx,y dalam ruang dimensi nn, rata-rata jarak didefinisikan dengan $$ d _ { a v e } = \\left ( \\frac { 1 } { n } \\sum _ { i = 1 } ^ { n } ( x _ { i } - y _ { i } ) ^ { 2 } \\right) ^ { \\frac { 1 } { 2 } } $$","title":"Average Distance"},{"location":"Mengukur Jarak Tipe Numerik/#weighted-euclidean-distance","text":"Jika berdasarkan tingkatan penting dari masing masing atribut ditentukan, maka Weighted Euclidean distance adalah modifikisasi lain dari jarak Euclidean distance yang dapat digunakan. Ukuran ini dirumuskan dengan $$ d _ { w e } = \\left ( \\sum _ { i = 1 } ^ { n } w _ { i } ( x _ { i } - y _ { i } \\right) ^ { 2 } ) ^ { \\frac { 1 } { 2 } } $$ dimana wiwi adalah bobot yang diberikan pada atribut ke i.","title":"Weighted euclidean distance"},{"location":"Mengukur Jarak Tipe Numerik/#chord-distance","text":"Chord distance adalah salah satu ukuran jarak modifikasi Euclidean distance untuk mengatasi kekurangan dari Euclidean distance. Ini dapat dipecahkan juga dengan menggunakan skala pengukuran yang baik. Jarak ini dapat juga dihitung dari data yang tidak dinormalisasi . Chord distance didefinisikan dengan $$ d _ { \\text {chord} } = \\left ( 2 - 2 \\frac { \\sum _ { i = 1 } ^ { n } x _ { i } y _ { i } } { | x | _ { 2 } | y | _ { 2 } } \\right) ^ { \\frac { 1 } { 2 } } $$","title":"Chord distance"},{"location":"Mengukur Jarak Tipe Numerik/#mahalanobis-distance","text":"Mahalanobis distance berdasarkan data berbeda dengan Euclidean dan Manhattan distances yang bebas antra data dengan data yang lain. Jarak Mahalanobis yang teratur dapat digunakan untuk mengekstraksi hyperellipsoidal clusters. Jarak Mahalanobis dapat mengurangi distorsi yang disebabkan oleh korelasi linier antara fitur dengan menerapkan transformasi pemutihan ke data atau dengan menggunakan kuadrat Jarak mahalanobis. Mahalanobis distance dinyatakan dengan $$ d _ { m a h } = \\sqrt { ( x - y ) S ^ { - 1 } ( x - y ) ^ { T } } $$ diman S adalah matrik covariance data.","title":"Mahalanobis distance"},{"location":"Mengukur Jarak Tipe Numerik/#cosine-measure","text":"Ukuran Cosine similarity lebih banyak digunakan dalam similaritas dokumen dan dinyatakan dengan $$ Cosine(x,y)=\\frac { \\sum _ { i = 1 } ^ { n } x _ { i } y _ { i } } { | x | _ { 2 } | y | _ { 2 } } $$","title":"Cosine measure"},{"location":"Mengukur Jarak Tipe Numerik/#pearson-correlation","text":"Pearson correlation banyak digunakan dalam data expresi gen. Ukuran similaritas ini menghitung similaritas antara duan bentuk pola expresi gen. Pearson correlation didefinisikan dengan $$ Pearson ( x , y ) = \\frac { \\sum _ { i = 1 } ^ { n } ( x _ { i } - \\mu _ { x } ) ( y _ { i } - \\mu _ { y } ) } { \\sqrt { \\sum _ { i = 1 } ^ { n } ( x _ { i } - y _ { i } ) ^ { 2 } } \\sqrt { \\sum _ { i = 1 } ^ { n } ( x _ { i } - y _ { i } ) ^ { 2 } } } $$","title":"Pearson correlation"},{"location":"Mengukur Jarak Tipe Numerik/#mengukur-jarak-atribut-binary","text":"Mari kita lihat similaritas dan desimilirity untuk objek yang dijelaskan oleh atribut biner simetris atau asimetris. Aatribut biner hanya memiliki dua status: 0 dan 1 Contoh atribut perokok menggambarkan seorang pasien, misalnya, 1 menunjukkan bahwa pasien merokok, sedangkan 0 menunjukkan pasien tidak merokok. Memperlakukan atribut biner sebagai atribut numerik tidak diperkenankan. Oleh karena itu, metode khusus untuk data biner diperlukan untuk membedakan komputasi. Jadi, bagaimana kita bisa menghitung ketidaksamaan antara dua atribut biner? \u201dSatu pendekatan melibatkan penghitungan matriks ketidaksamaan dari data biner yang diberikan. Jika semua atribut biner dianggap memiliki bobot yang sama, kita memiliki tabel kontingensi 2\u00d722\u00d72 di mana qq adalah jumlah atribut yang sama dengan 1 untuk kedua objek ii dan jj, rr adalah jumlah atribut yang sama dengan 1 untuk objek ii tetapi 0 untuk objek jj, ss adalah jumlah atribut yang sama dengan 0 untuk objek ii tetapi 1 untuk objek jj, dan tt adalah jumlah atribut yang sama dengan 0 untuk kedua objek ii dan jj. Jumlah total atribut adalah pp, di mana p=q+r+s+tp=q+r+s+t Ingatlah bahwa untuk atribut biner simetris, masing-masing nilai bobot yang sama.Dissimilarity yang didasarkan pada atribut aymmetric binary disebut symmetric binary dissimilarity. Jika objek i dan j dinyatakan sebagai atribut biner simetris, maka dissimilarity antarii dan jj adalah $$ d ( i , j ) = \\frac { r + s } { q + r + s + t } $$ Untuk atribut biner asimetris, kedua kondisi tersebut tidak sama pentingnya, seperti hasil positif (1) dan negatif (0) dari tes penyakit. Diberikan dua atribut biner asimetris, pencocokan keduanya 1 (kecocokan positif) kemudian dianggap lebih signifikan daripada kecocokan negatif. Ketidaksamaan berdasarkan atribut-atribut ini disebut asimetris biner dissimilarity, di mana jumlah kecocokan negatif, t, dianggap tidak penting dan dengan demikian diabaikan. Berikut perhitungannya $$ d ( i , j ) = \\frac { r + s } { q + r + s } $$ Kita dapat mengukur perbedaan antara dua atribut biner berdasarkan pada disimilarity. Misalnya, biner asimetris kesamaan antara objek ii dan jj dapat dihitung dengan $$ \\operatorname { sim } ( i , j ) = \\frac { q } { q + r + s } = 1 - d ( i , j ) $$","title":"Mengukur Jarak Atribut Binary"},{"location":"Mengukur Jarak Tipe Numerik/#mengukur-jarak-tipe-categorical","text":"","title":"Mengukur Jarak Tipe categorical"},{"location":"Mengukur Jarak Tipe Numerik/#overlay-metric","text":"Ketika semua atribut adalah bertipe nominal, ukuran jarak yang paling sederhana adalah dengan Ovelay Metric (OM) yang dinyatakan dengan $$ d ( x , y ) = \\sum _ { i = 1 } ^ { n } \\delta ( a _ { i } ( x ) , a _ { i } ( y ) ) $$ OM banyak digunakan oleh instance-based learning dan locally weighted learning. Jelas sekali , ini sedikit beruk untuk mengukur jarak antara masing-masing pasangan sample, karena gagal memanfaatkan tambahan informasi yang diberikan oleh nilai atribut nominal yang bisa membantu dalam generalisasi.","title":"Overlay Metric"},{"location":"Mengukur Jarak Tipe Numerik/#value-difference-metric-vdm","text":"VDM dikenalkan oleh Standfill and Waltz, versi sederhana dari VDM tanpa skema pembobotan didefinsisikan dengan $$ d ( x , y ) = \\sum _ { i = 1 } ^ { n } \\sum _ { c = 1 } ^ { C } \\left| P ( c | a _ { i } ( x ) ) - P ( c | a _ { i } ( y ) ) \\right | $$ VDM mengasumsikan bahwa dua nilai dari atribut adalah lebih dekat jika memiliki klasifikasi sama. Pendekatan lain berbasi probabilitas adalah SFM (Short and Fukunaga Metric) yang kemudian dikembangkan oleh Myles dan Hand dan didefinisikan dengan $$ d ( x , y ) = \\sum _ { c = 1 } ^ { C } \\left | P ( c | x ) - P ( c | y ) \\right| $$","title":"Value Difference Metric (VDM)"},{"location":"Mengukur Jarak Tipe Numerik/#minimum-risk-metric-mrm","text":"Ukuran ini dipresentasikan oleh Blanzieri and Ricci, berbeda dari SFM yaitu meminimumkan selisih antara kesalahan berhingga dan kesalahan asymtotic. MRM meminimumkan risk of misclassification yang didefinisikan dengan $$ d ( x , y ) = \\sum _ { c = 1 } ^ { C } P ( c | x ) ( 1 - P ( c | y ) ) $$","title":"Minimum Risk Metric (MRM)"},{"location":"Mengukur Jarak Tipe Numerik/#mengukur-jarak-tipe-ordinal","text":"Nilai-nilai atribut ordinal memiliki urutan atau peringkat, namun besarnya antara nilai-nilai berturut-turut tidak diketahui. Contohnya tingkatan kecil, sedang, besar untuk atribut ukuran. Atribut ordinal juga dapat diperoleh dari diskritisasi atribut numerik dengan membuat rentang nilai ke dalam sejumlah kategori tertentu. $$ z _ { i f } = \\frac { r _ { i f } - 1 } { M _ { f } - 1 } $$","title":"Mengukur Jarak Tipe Ordinal"},{"location":"Mengukur Jarak Tipe Numerik/#menghitung-jarak-tipe-campuran","text":"Menghitung ketidaksamaan antara objek dengan atribut campuran yang berupa nominal, biner simetris, biner asimetris, numerik, atau ordinal yang ada pada kebanyakan databasae dapat dinyatakan dengan memproses semua tipe atribut secara bersamaan. Salah satu teknik tersebut menggabungkan atribut yang berbeda ke dalam matriks ketidaksamaan tunggal dan menyatakannya dengan skala interval antar [0,0,1.0][0,0,1.0]. Misalkan data berisi atribut pp tipe campuran. Ketidaksamaan (disimilarity ) antara objek ii dan jj dinyatakan dengan $$ d ( i , j ) = \\frac { \\sum _ { f = 1 } ^ { p } \\delta _ { i j } ^ { ( f ) } d _ { i j } ^ { ( f ) } } { \\sum _ { f = 1 } ^ { p } \\delta _ { i j } ^ { ( f ) } } $$","title":"Menghitung Jarak Tipe Campuran"},{"location":"pengertian/","text":"STATISTIK DESKRIPTIF \u00b6 pengertian \u00b6 STATISTIK DEKRIPTIF ADALAH metode pengumpulan sebuah data data yang akan menghasilkan informasi yang berguna TIPE STATISTIK DESKRIPTIF \u00b6 MEAN(RATA-RATA) \u00b6 mean atau rata rata adalah hasil dari nilai yang dijumlah, dari seluruah angka atau data dan di bagi banyak data . Contohnya nilai N yang memiliki jumlah data di kisaran berapapun. rata-rata bisa di hitung dengan rumus sebagai berikut $$ \\begin{align} \\bar{X} = \\frac{1}{n} \\sum_{i=1}^n X_i={a_1+a_2+a_3+a_4+........+a_n \\over n} \\end{align} $$ keterangan: x=rata-rata a=nilai ke N n=banyak nilai atau data MEDIAN \u00b6 median merupakan nilai tengah (pusat data) dalam suatu data median biasanya bisa disebut Me .menghitung median mempunyai 2 metode yaitu ketika N atau jumlah data ganjil atau genap. saat data ganjil dan data genap perhitingan nya berbeda.berikut rumus median yang dapat di gunakan : $$ Me=Q_2 =\\left( \\begin{matrix} n+1 \\over 2 \\end{matrix} \\right), jika\\quad n\\quad ganjil $$ $$ Me=Q_2 =\\left( \\begin{matrix} {xn \\over 2 } {xn+1\\over 2} \\over 2 \\end{matrix} \\right), jika\\quad n\\quad genap $$ ket: me =median atau nilai tengah n=banyak data MODUS \u00b6 Modus adalah nilai yang sering muncul dalam himpunan data dan jika hasil dengan jumlah nilai tertinggi maka itu merupakan modus dari himpunan angka. brikut ini rumus mencari modus dalam himpunan data : $$ M_o = Tb + p{b_1 \\over b_1 + b_2} $$ ket; mo=nilai modus tb= tepi bawah b1=selisih frekuensi antara nilai mudus dengan elemen sebelumnya b2=selisih frekuensi antara nilai mudus dengan elemen sesudahnya p= panjang interval varian \u00b6 varians adalah ukuran seberapa jauh suatu kumpulan bilangan tersebar, varian merupakan jumlah kuadrat semua deviasi nilai-nilai terhadap rata-rata. $$ \\sigma^2 = {\\sum \\limits_{i=1}^{n} (x_i - \\bar x)^2 \\over n} $$ ket: x=rata rata Xi=rata rata dari semua titik data n= banyak dari anggota data Standar Defiasi \u00b6 Standar deviasi adalah ukuran kumpulan data relatif terhadap rata-rata atau akar kuadrat positif dari varian. standar deviasi di hitung dengan cara mengakar kuadrat nilai dari varians. dengan menggunakan rumus standar varian berikut : $$ t {{\\sum \\limits_{i=1}^{n} (x_i - \\bar x)^2 \\over n}} $$ skewness \u00b6 Skewness merupakan bentuk ketidaksimetrisan suatu distribusi data. Skewness juga adaalah angka yang menujukkan ketidak miringan atau kemiringan suatu data. $$ {\\sum \\limits{i=1}^n (x_i - \\bar x)^i \\over (n- 1) \\sigma^3} $$ Quartil \u00b6 Quartile adalah irisan nilai dari hasil pembagian data menjadi empat bagian yang sama besar.quartil terbagi menjadi tiga yaitu quartil pertama,kedua,dan ketiga. $$ Q_1 = (n + 1) {1\\over 4} $$ $$ Q_2 = (n + 1) {1\\over 2} $$ $$ Q_3 = (n + 1) {3\\over 4} $$ Penerapan Statistik Deskriptif Menggunakan Python \u00b6 Alat dan bahan \u00b6 buatlah data dengan random di excel terleih dahulu, caranya dengan menggunakan formula =RANDBETWEEN(batas_bawah;batas_atas) . kemudian copast hasil tersebut sebagai values . Setelah itu save as .csv . kita menggunakan library python yakni, pandas dan scipy. import pandas as pd from scipy import stats df = pd . read_csv ( 'imam.csv' , sep = ';' ) data = { \"stats\" :[ 'Min' , 'Max' , 'Mean' , 'Standart Deviasi' , 'Variasi' , 'Skewnes' , 'Quantile 1' , 'Quantile 2' , 'Quantile 3' , 'Median' , 'Modus' ]} for i in df . columns : data [ i ] = [ df [ i ] . min (), df [ i ] . max (), df [ i ] . mean (), round ( df [ i ] . std (), 2 ), round ( df [ i ] . var (), 2 ), round ( df [ i ] . skew (), 2 ), df [ i ] . quantile ( 0.25 ), df [ i ] . quantile ( 0.5 ), df [ i ] . quantile ( 0.75 ), df [ i ] . median (), stats . mode ( df [ i ]) . mode [ 0 ]] tes = pd . DataFrame ( data ) tes . style . hide_index () stats ukuran baju ukuran sepatu ukaran celana umur Min 18 27 22 20 Max 30 42 36 40 Mean 23.76 34.452 28.812 29.828 Standart Deviasi 3.75 4.64 4.23 6.18 Variasi 14.05 21.53 17.93 38.18 Skewnes 0.08 0.02 0.08 -0 Quantile 1 21 30.75 25 24 Quantile 2 24 34 29 30 Quantile 3 27 39 32 35 Median 24 34 29 30 Modus 21 32 26 24 MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$']]} });","title":"Pengertian"},{"location":"pengertian/#statistik-deskriptif","text":"","title":"STATISTIK DESKRIPTIF"},{"location":"pengertian/#pengertian","text":"STATISTIK DEKRIPTIF ADALAH metode pengumpulan sebuah data data yang akan menghasilkan informasi yang berguna","title":"pengertian"},{"location":"pengertian/#tipe-statistik-deskriptif","text":"","title":"TIPE STATISTIK DESKRIPTIF"},{"location":"pengertian/#meanrata-rata","text":"mean atau rata rata adalah hasil dari nilai yang dijumlah, dari seluruah angka atau data dan di bagi banyak data . Contohnya nilai N yang memiliki jumlah data di kisaran berapapun. rata-rata bisa di hitung dengan rumus sebagai berikut $$ \\begin{align} \\bar{X} = \\frac{1}{n} \\sum_{i=1}^n X_i={a_1+a_2+a_3+a_4+........+a_n \\over n} \\end{align} $$ keterangan: x=rata-rata a=nilai ke N n=banyak nilai atau data","title":"MEAN(RATA-RATA)"},{"location":"pengertian/#median","text":"median merupakan nilai tengah (pusat data) dalam suatu data median biasanya bisa disebut Me .menghitung median mempunyai 2 metode yaitu ketika N atau jumlah data ganjil atau genap. saat data ganjil dan data genap perhitingan nya berbeda.berikut rumus median yang dapat di gunakan : $$ Me=Q_2 =\\left( \\begin{matrix} n+1 \\over 2 \\end{matrix} \\right), jika\\quad n\\quad ganjil $$ $$ Me=Q_2 =\\left( \\begin{matrix} {xn \\over 2 } {xn+1\\over 2} \\over 2 \\end{matrix} \\right), jika\\quad n\\quad genap $$ ket: me =median atau nilai tengah n=banyak data","title":"MEDIAN"},{"location":"pengertian/#modus","text":"Modus adalah nilai yang sering muncul dalam himpunan data dan jika hasil dengan jumlah nilai tertinggi maka itu merupakan modus dari himpunan angka. brikut ini rumus mencari modus dalam himpunan data : $$ M_o = Tb + p{b_1 \\over b_1 + b_2} $$ ket; mo=nilai modus tb= tepi bawah b1=selisih frekuensi antara nilai mudus dengan elemen sebelumnya b2=selisih frekuensi antara nilai mudus dengan elemen sesudahnya p= panjang interval","title":"MODUS"},{"location":"pengertian/#varian","text":"varians adalah ukuran seberapa jauh suatu kumpulan bilangan tersebar, varian merupakan jumlah kuadrat semua deviasi nilai-nilai terhadap rata-rata. $$ \\sigma^2 = {\\sum \\limits_{i=1}^{n} (x_i - \\bar x)^2 \\over n} $$ ket: x=rata rata Xi=rata rata dari semua titik data n= banyak dari anggota data","title":"varian"},{"location":"pengertian/#standar-defiasi","text":"Standar deviasi adalah ukuran kumpulan data relatif terhadap rata-rata atau akar kuadrat positif dari varian. standar deviasi di hitung dengan cara mengakar kuadrat nilai dari varians. dengan menggunakan rumus standar varian berikut : $$ t {{\\sum \\limits_{i=1}^{n} (x_i - \\bar x)^2 \\over n}} $$","title":"Standar Defiasi"},{"location":"pengertian/#skewness","text":"Skewness merupakan bentuk ketidaksimetrisan suatu distribusi data. Skewness juga adaalah angka yang menujukkan ketidak miringan atau kemiringan suatu data. $$ {\\sum \\limits{i=1}^n (x_i - \\bar x)^i \\over (n- 1) \\sigma^3} $$","title":"skewness"},{"location":"pengertian/#quartil","text":"Quartile adalah irisan nilai dari hasil pembagian data menjadi empat bagian yang sama besar.quartil terbagi menjadi tiga yaitu quartil pertama,kedua,dan ketiga. $$ Q_1 = (n + 1) {1\\over 4} $$ $$ Q_2 = (n + 1) {1\\over 2} $$ $$ Q_3 = (n + 1) {3\\over 4} $$","title":"Quartil"},{"location":"pengertian/#penerapan-statistik-deskriptif-menggunakan-python","text":"","title":"Penerapan Statistik Deskriptif Menggunakan Python"},{"location":"pengertian/#alat-dan-bahan","text":"buatlah data dengan random di excel terleih dahulu, caranya dengan menggunakan formula =RANDBETWEEN(batas_bawah;batas_atas) . kemudian copast hasil tersebut sebagai values . Setelah itu save as .csv . kita menggunakan library python yakni, pandas dan scipy. import pandas as pd from scipy import stats df = pd . read_csv ( 'imam.csv' , sep = ';' ) data = { \"stats\" :[ 'Min' , 'Max' , 'Mean' , 'Standart Deviasi' , 'Variasi' , 'Skewnes' , 'Quantile 1' , 'Quantile 2' , 'Quantile 3' , 'Median' , 'Modus' ]} for i in df . columns : data [ i ] = [ df [ i ] . min (), df [ i ] . max (), df [ i ] . mean (), round ( df [ i ] . std (), 2 ), round ( df [ i ] . var (), 2 ), round ( df [ i ] . skew (), 2 ), df [ i ] . quantile ( 0.25 ), df [ i ] . quantile ( 0.5 ), df [ i ] . quantile ( 0.75 ), df [ i ] . median (), stats . mode ( df [ i ]) . mode [ 0 ]] tes = pd . DataFrame ( data ) tes . style . hide_index () stats ukuran baju ukuran sepatu ukaran celana umur Min 18 27 22 20 Max 30 42 36 40 Mean 23.76 34.452 28.812 29.828 Standart Deviasi 3.75 4.64 4.23 6.18 Variasi 14.05 21.53 17.93 38.18 Skewnes 0.08 0.02 0.08 -0 Quantile 1 21 30.75 25 24 Quantile 2 24 34 29 30 Quantile 3 27 39 32 35 Median 24 34 29 30 Modus 21 32 26 24 MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$']]} });","title":"Alat dan bahan"}]}